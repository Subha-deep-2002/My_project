<!-- index.html -->
<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>Drowsiness Detection</title>
  <style>
    body { font-family: Arial, sans-serif; text-align: center; margin: 40px; }
    h1   { font-weight: bold; margin-bottom: 20px; }
    .video-container { display: flex; justify-content: center; align-items: center; }
    video   { width:100%; max-width:600px; border-radius:8px; display:none; }
    canvas  { display:none; }
    button {
      padding:15px 25px; font-size:18px; margin:10px; cursor:pointer;
      border:none; border-radius:5px; color:white; transition:background-color 0.3s;
    }
    #calibrate-btn { background-color:#007bff; }
    #calibrate-btn:hover { background-color:#0069d9; }
    #start-btn { background-color:#28a745; }
    #start-btn:hover { background-color:#218838; }
    #stop-btn { background-color:#dc3545; }
    #stop-btn:hover { background-color:#c82333; }
    button:disabled { background-color:#6c757d; cursor:not-allowed; }
    #status { font-size:20px; margin-top:10px; }
  </style>
</head>
<body>
  <h1>Drowsiness Detection</h1>
  <div class="video-container">
    <video id="video" autoplay muted></video>
  </div>
  <canvas id="canvas"></canvas>
  <p id="status">Click ‚ÄúCalibrate‚Äù to begin.</p>

  <button id="calibrate-btn">Calibrate</button>
  <button id="start-btn" disabled>Start Detection</button>
  <button id="stop-btn" disabled>Stop Detection</button>

  <audio id="alert-audio" src="static/music.wav" preload="auto"></audio>

  <script>
    const calibrateBtn = document.getElementById('calibrate-btn');
    const startBtn     = document.getElementById('start-btn');
    const stopBtn      = document.getElementById('stop-btn');
    const video        = document.getElementById('video');
    const canvas       = document.getElementById('canvas');
    const statusText   = document.getElementById('status');
    const alertAudio   = document.getElementById('alert-audio');

    let calibrateInterval, detectInterval;

    // Wait for camera and video element to be ready
    async function startCamera() {
      try {
        const stream = await navigator.mediaDevices.getUserMedia({ video: true });
        video.srcObject = stream;
        video.style.display = 'block';
        await video.play();
      } catch (err) {
        alert('Error accessing webcam: ' + err);
      }
    }

    // One calibration step: send current frame
    async function calibrateStep() {
      const ctx = canvas.getContext('2d');
      canvas.width  = video.videoWidth;
      canvas.height = video.videoHeight;
      ctx.drawImage(video, 0, 0);
      canvas.toBlob(async blob => {
        const form = new FormData();
        form.append('frame', blob, 'frame.jpg');
        try {
          const res  = await fetch('/calibrate', { method: 'POST', body: form });
          const data = await res.json();
          if (data.error) {
            statusText.textContent = 'Calibration Error: ' + data.error;
            clearInterval(calibrateInterval);
            return;
          }
          if (data.calibrated) {
            clearInterval(calibrateInterval);
            statusText.textContent = `Calibrated! Threshold = ${data.threshold.toFixed(2)}`;
            calibrateBtn.disabled = true;
            startBtn.disabled     = false;
          } else {
            statusText.textContent = `Calibrating‚Ä¶ (${data.collected}/${data.needed})`;
          }
        } catch (e) {
          statusText.textContent = 'Network error: ' + e;
          clearInterval(calibrateInterval);
        }
      }, 'image/jpeg');
    }

    calibrateBtn.addEventListener('click', async () => {
      await startCamera();
      statusText.textContent = 'Starting calibration‚Ä¶';
      calibrateInterval = setInterval(calibrateStep, 200);
      calibrateBtn.disabled = true;
      startBtn.disabled     = true;
      stopBtn.disabled      = false;
    });

    // One detection step: send current frame
    async function detectionStep() {
      const ctx = canvas.getContext('2d');
      canvas.width  = video.videoWidth;
      canvas.height = video.videoHeight;
      ctx.drawImage(video, 0, 0);
      canvas.toBlob(async blob => {
        const form = new FormData();
        form.append('frame', blob, 'frame.jpg');
        const res  = await fetch('/process', { method: 'POST', body: form });
        const data = await res.json();
        if (data.error) {
          statusText.textContent = 'Error: ' + data.error;
          return;
        }
        if (data.ear !== null) {
          statusText.textContent =
            `EAR: ${data.ear.toFixed(2)} (thresold ${data.threshold.toFixed(2)}) ‚Äî ` +
            (data.alert ? 'üò¥ Drowsy!' : 'üôÇ Awake');
          if (data.alert) {
            if (alertAudio.paused) alertAudio.play();
          } else {
            alertAudio.pause();
            alertAudio.currentTime = 0;
          }
        } else {
          statusText.textContent = 'No face detected';
        }
      }, 'image/jpeg');
    }

    startBtn.addEventListener('click', () => {
      statusText.textContent = 'Detection running‚Ä¶';
      detectInterval = setInterval(detectionStep, 500);
      startBtn.disabled = true;
      stopBtn.disabled  = false;
    });

    stopBtn.addEventListener('click', () => {
      clearInterval(calibrateInterval);
      clearInterval(detectInterval);
      video.style.display = 'none';
      if (video.srcObject) {
        video.srcObject.getTracks().forEach(t => t.stop());
        video.srcObject = null;
      }
      alertAudio.pause();
      alertAudio.currentTime = 0;
      calibrateBtn.disabled = false;
      startBtn.disabled     = true;
      stopBtn.disabled      = true;
      statusText.textContent = 'Stopped. Click ‚ÄúCalibrate‚Äù to start again.';
    });
  </script>
</body>
</html>
